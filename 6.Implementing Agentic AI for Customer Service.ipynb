{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7412ed9c-d4da-458a-a994-fd36aa0d31be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "#Install prerequisite packages\n",
    "!pip install python-dotenv==1.0.0\n",
    "\n",
    "!pip install llama-index==0.10.59\n",
    "!pip install llama-index-llms-openai==0.1.27\n",
    "!pip install llama-index-embeddings-openai==0.1.11\n",
    "!pip install llama-index-llms-azure-openai==0.1.10\n",
    "!pip install llama-index-embeddings-azure-openai==0.1.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77f7952-5a00-44cc-9cc7-7623412ad8d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Setup Azure Open AI connection\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "from llama_index.core import Settings\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#API info. Replace with your own keys and end points\n",
    "api_key=\"\"\n",
    "azure_endpoint=\"\"\n",
    "azure_deployment=\"GPT4-O\"\n",
    "api_version=\"2024-12-01-preview\"\n",
    "\n",
    "#Setup the LLM\n",
    "Settings.llm=AzureOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=azure_deployment,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "#Setup the embedding model RAG\n",
    "Settings.embed_model= AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key='',\n",
    "    azure_endpoint='',\n",
    "    api_version='2023-05-15',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ac1604a-0a15-4254-af66-429a61d7c04b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-710c90cf1c3f4514b23cd8ad57991953\", \"tr-97620c7360604d81952bbbae00c738c4\"]",
      "text/plain": [
       "[Trace(request_id=tr-710c90cf1c3f4514b23cd8ad57991953), Trace(request_id=tr-97620c7360604d81952bbbae00c738c4)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import  VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Tool 1 : Function that returns the list of items in an order\n",
    "#-------------------------------------------------------------\n",
    "def get_order_items(order_id: int) -> List[str] :\n",
    "    \"\"\"Given an order Id, this function returns the \n",
    "    list of items purchased for that order\"\"\"\n",
    "    \n",
    "    order_items = {\n",
    "            1001: [\"Laptop\",\"Mouse\"],\n",
    "            1002: [\"Keyboard\",\"HDMI Cable\"],\n",
    "            1003: [\"Laptop\",\"Keyboard\"]\n",
    "        }\n",
    "    if order_id in order_items.keys():\n",
    "        return order_items[order_id]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Tool 2 : Function that returns the delivery date for an order\n",
    "#-------------------------------------------------------------\n",
    "def get_delivery_date(order_id: int) -> str:\n",
    "    \"\"\"Given an order Id, this function returns the \n",
    "    delivery date for that order\"\"\"\n",
    "\n",
    "    delivery_dates = {\n",
    "            1001: \"10-Jun\",\n",
    "            1002: \"12-Jun\",\n",
    "            1003: \"08-Jun\"       \n",
    "    }\n",
    "    if order_id in delivery_dates.keys():\n",
    "        return delivery_dates[order_id]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Tool 3 : Function that returns maximum return days for an item\n",
    "#----------------------------------------------------------------\n",
    "def get_item_return_days(item: str) -> int :\n",
    "    \"\"\"Given an Item, this function returns the return support\n",
    "    for that order. The return support is in number of days\"\"\"\n",
    "    \n",
    "    item_returns = {\n",
    "            \"Laptop\"     : 30,\n",
    "            \"Mouse\"      : 15,\n",
    "            \"Keyboard\"   : 15,\n",
    "            \"HDMI Cable\" : 5\n",
    "    }\n",
    "    if item in item_returns.keys():\n",
    "        return item_returns[item]\n",
    "    else:\n",
    "        #Default\n",
    "        return 45\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Tool 4 : Vector DB that contains customer support contacts\n",
    "#-------------------------------------------------------------\n",
    "#Setup vector index for return policies\n",
    "support_docs=SimpleDirectoryReader(input_files=[\"/Workspace/Users/yfatima1@optumcloud.com/Customer Service.pdf\"]).load_data()\n",
    "\n",
    "splitter=SentenceSplitter(chunk_size=1024)\n",
    "support_nodes=splitter.get_nodes_from_documents(support_docs)\n",
    "support_index=VectorStoreIndex(support_nodes)\n",
    "support_query_engine = support_index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc8b3d9-b9ed-4bcb-9d71-c71c644d9154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "#Create tools for the 3 functions and 1 index\n",
    "order_item_tool = FunctionTool.from_defaults(fn=get_order_items)\n",
    "delivery_date_tool = FunctionTool.from_defaults(fn=get_delivery_date)\n",
    "return_policy_tool = FunctionTool.from_defaults(fn=get_item_return_days)\n",
    "\n",
    "support_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=support_query_engine,\n",
    "    description=(\n",
    "        \"Customer support policies and contact information\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69aeeca4-abd7-4efb-8030-5a752b09512a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#Setup the Agent worker in LlamaIndex with all the Tools\n",
    "#This is the tool executor process\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [order_item_tool, \n",
    "     delivery_date_tool,\n",
    "     return_policy_tool,\n",
    "     support_tool\n",
    "    ], \n",
    "    llm=Settings.llm, \n",
    "    verbose=True\n",
    ")\n",
    "#Create an Agent Orchestrator with LlamaIndex\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2648ed41-81a4-40f2-8cb6-12148ee7fcdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the return policy for order number 1001\n=== Calling Function ===\nCalling function: get_order_items with args: {\"order_id\": 1001}\n=== Function Output ===\n['Laptop', 'Mouse']\n=== Calling Function ===\nCalling function: get_delivery_date with args: {\"order_id\": 1001}\n=== Function Output ===\n10-Jun\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:20:48 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\nCalling function: get_item_return_days with args: {\"item\": \"Laptop\"}\n=== Function Output ===\n30\n=== Calling Function ===\nCalling function: get_item_return_days with args: {\"item\": \"Mouse\"}\n=== Function Output ===\n15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:20:49 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\nFor order number 1001, the items purchased are a Laptop and a Mouse. The return policy for these items is as follows:\n\n- **Laptop**: You can return the laptop within 30 days from the delivery date.\n- **Mouse**: You can return the mouse within 15 days from the delivery date.\n\nThe delivery date for this order was June 10th.\n\n Final output : \n For order number 1001, the items purchased are a Laptop and a Mouse. The return policy for these items is as follows:\n\n- **Laptop**: You can return the laptop within 30 days from the delivery date.\n- **Mouse**: You can return the mouse within 15 days from the delivery date.\n\nThe delivery date for this order was June 10th.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-bc1810ebbc864c16a4c14e66fe5196ff\"",
      "text/plain": [
       "Trace(request_id=tr-bc1810ebbc864c16a4c14e66fe5196ff)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get return policy for an order\n",
    "response = agent.query(\n",
    "    \"What is the return policy for order number 1001\"\n",
    ")\n",
    "\n",
    "print(\"\\n Final output : \\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a751a15-0797-455e-a30b-25aff6de6af9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the return policy for order number 1004\n=== Calling Function ===\nCalling function: get_order_items with args: {\"order_id\": 1004}\n=== Function Output ===\n[]\n=== Calling Function ===\nCalling function: get_delivery_date with args: {\"order_id\": 1004}\n=== Function Output ===\n[]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:21:46 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\nCalling function: query_engine_tool with args: {\"input\": \"return policy\"}\n=== Function Output ===\nThe context does not provide information regarding the return policy.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:21:47 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\nIt seems that there is no specific information available for order number 1004, and the general return policy details are not provided either. You may want to contact customer support for more information on return policies.\n\n Final output : \n It seems that there is no specific information available for order number 1004, and the general return policy details are not provided either. You may want to contact customer support for more information on return policies.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-b59bb30bb7d94ec193656a73e8a7dde9\"",
      "text/plain": [
       "Trace(request_id=tr-b59bb30bb7d94ec193656a73e8a7dde9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question about an invalid order number\n",
    "response = agent.query(\n",
    "    \"What is the return policy for order number 1004\"\n",
    ")\n",
    "\n",
    "print(\"\\n Final output : \\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0390e743-09ff-435b-b904-33377ed27c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Implementing Agentic AI for Customer Service",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
