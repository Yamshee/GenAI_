{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7412ed9c-d4da-458a-a994-fd36aa0d31be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv==1.0.0\n  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\nUsing cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-1.0.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting llama-index==0.10.59\n  Using cached llama_index-0.10.59-py3-none-any.whl.metadata (11 kB)\nCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.59)\n  Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\nCollecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.59)\n  Using cached llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core==0.10.59 (from llama-index==0.10.59)\n  Using cached llama_index_core-0.10.59-py3-none-any.whl.metadata (2.4 kB)\nCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.59)\n  Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\nCollecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.59)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.59)\n  Using cached llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index==0.10.59)\n  Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\nCollecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.59)\n  Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.59)\n  Using cached llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\nCollecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.59)\n  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.59)\n  Using cached llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index-readers-llama-parse>=0.1.2 (from llama-index==0.10.59)\n  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: PyYAML>=6.0.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (6.0.1)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index==0.10.59) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (3.9.5)\nCollecting dataclasses-json (from llama-index-core==0.10.59->llama-index==0.10.59)\n  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: deprecated>=1.2.9.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.2.18)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.59->llama-index==0.10.59)\n  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (2023.5.0)\nRequirement already satisfied: httpx in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (0.28.1)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (3.2.1)\nRequirement already satisfied: nltk<4.0.0,>=3.8.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (3.8.1)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.26.4)\nRequirement already satisfied: openai>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.69.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.5.3)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (10.3.0)\nRequirement already satisfied: requests>=2.31.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (2.32.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (8.2.2)\nRequirement already satisfied: tiktoken>=0.3.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (0.7.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.5.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (4.11.0)\nCollecting typing-inspect>=0.8.0 (from llama-index-core==0.10.59->llama-index==0.10.59)\n  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.14.1)\nCollecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59)\n  Using cached llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\nINFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.59)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.10-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.7-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.6-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.5-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\nINFO: pip is still looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n  Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.2-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.1-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.6.0-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.5.0-py3-none-any.whl.metadata (3.8 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Using cached llama_index_indices_managed_llama_cloud-0.4.2-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.4.1-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n  Using cached llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59) (4.12.3)\nCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59)\n  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59)\n  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nINFO: pip is looking at multiple versions of llama-index-readers-llama-parse to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-readers-llama-parse>=0.1.2 (from llama-index==0.10.59)\n  Using cached llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_index_readers_llama_parse-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n  Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.23-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (1.9.3)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59) (2.5)\nCollecting certifi>=2024.7.4 (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59)\n  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pydantic>=1.10 in /databricks/python3/lib/python3.12/site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (2.8.2)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index==0.10.59) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index==0.10.59) (1.0.8)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index==0.10.59) (3.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.59->llama-index==0.10.59) (0.14.0)\nCollecting llama-cloud-services>=0.6.23 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index==0.10.59) (8.1.7)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index==0.10.59) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index==0.10.59) (2023.10.3)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index==0.10.59) (0.9.0)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama-index==0.10.59) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.26.16)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index==0.10.59) (3.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.0.0)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.59->llama-index==0.10.59)\n  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index==0.10.59) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index==0.10.59) (2024.1)\nINFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.22 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59)\n  Using cached llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.21 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.20-py3-none-any.whl.metadata (6.9 kB)\nINFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-cloud-services>=0.6.20 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.20-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.18-py3-none-any.whl.metadata (6.9 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\nCollecting llama-cloud-services>=0.6.17 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.19-py3-none-any.whl.metadata (3.4 kB)\n  Using cached llama_cloud_services-0.6.18-py3-none-any.whl.metadata (3.4 kB)\n  Using cached llama_cloud_services-0.6.17-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.16-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.16 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.16-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.12 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.15-py3-none-any.whl.metadata (3.4 kB)\n  Using cached llama_cloud_services-0.6.14-py3-none-any.whl.metadata (3.4 kB)\n  Using cached llama_cloud_services-0.6.12-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.9-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.9 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.11-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_cloud_services-0.6.10-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.4 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.8-py3-none-any.whl.metadata (2.9 kB)\n  Using cached llama_cloud_services-0.6.7-py3-none-any.whl.metadata (2.9 kB)\n  Using cached llama_cloud_services-0.6.6-py3-none-any.whl.metadata (2.9 kB)\n  Using cached llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n  Using cached llama_cloud_services-0.6.4-py3-none-any.whl.metadata (2.9 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.4-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.3 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.2 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.2-py3-none-any.whl.metadata (2.8 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.1 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting llama-cloud-services (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59)\n  Using cached llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\nINFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n  Using cached llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n  Using cached llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n  Using cached llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n  Using cached llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n  Using cached llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n  Using cached llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\nINFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n  Using cached llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Using cached llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n  Using cached llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n  Using cached llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n  Using cached llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n  Using cached llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n  Using cached llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n  Using cached llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n  Using cached llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n  Using cached llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.59->llama-index==0.10.59) (24.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (2.20.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core==0.10.59->llama-index==0.10.59) (1.16.0)\nUsing cached llama_index-0.10.59-py3-none-any.whl (6.8 kB)\nUsing cached llama_index_core-0.10.59-py3-none-any.whl (15.5 MB)\nUsing cached llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\nUsing cached llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\nUsing cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\nUsing cached llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\nUsing cached llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\nUsing cached llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\nUsing cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\nUsing cached llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\nUsing cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\nUsing cached llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\nUsing cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\nUsing cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nUsing cached llama_cloud-0.1.22-py3-none-any.whl (265 kB)\nUsing cached llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\nUsing cached pypdf-4.3.1-py3-none-any.whl (295 kB)\nUsing cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nUsing cached certifi-2025.4.26-py3-none-any.whl (159 kB)\nUsing cached marshmallow-3.26.1-py\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.9.5)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.2.18)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.0.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2023.5.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.2.1)\nRequirement already satisfied: nltk<4.0.0,>=3.8.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.8.1)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.26.4)\nRequirement already satisfied: openai>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.69.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.5.3)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (10.3.0)\nRequirement already satisfied: requests>=2.31.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.32.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (8.2.2)\nRequirement already satisfied: tiktoken>=0.3.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.7.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (4.66.4)\nRequirement already satisfied: typing-inspect>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.9.0)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.14.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-llms-azure-openai==0.1.10) (4.2.0)\nRequirement already satisfied: certifi in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from httpx->llama-index-llms-azure-openai==0.1.10) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-llms-azure-openai==0.1.10) (1.0.8)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-llms-azure-openai==0.1.10) (3.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai==0.1.10) (0.14.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.9.3)\nRequirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core>=1.31.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.16.0)\nRequirement already satisfied: PyJWT<3,>=1.0.0 in /usr/lib/python3/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (2.7.0)\nRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (8.1.7)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2023.10.3)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.9.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.8.2)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.26.16)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.26.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2024.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (2.21)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (24.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.20.1)\nUsing cached llama_index_llms_azure_openai-0.1.10-py3-none-any.whl (5.1 kB)\nInstalling collected packages: llama-index-llms-azure-openai\nSuccessfully installed llama-index-llms-azure-openai-0.1.10\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting llama-index-embeddings-azure-openai==0.1.11\n  Using cached llama_index_embeddings_azure_openai-0.1.11-py3-none-any.whl.metadata (804 bytes)\nRequirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-embeddings-azure-openai==0.1.11) (0.10.59)\nRequirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-embeddings-azure-openai==0.1.11) (0.1.11)\nRequirement already satisfied: llama-index-llms-azure-openai<0.2.0,>=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-embeddings-azure-openai==0.1.11) (0.1.10)\nRequirement already satisfied: PyYAML>=6.0.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (6.0.1)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.9.5)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.2.18)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.0.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2023.5.0)\nRequirement already satisfied: httpx in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.28.1)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.2.1)\nRequirement already satisfied: nltk<4.0.0,>=3.8.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.8.1)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.26.4)\nRequirement already satisfied: openai>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.69.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.5.3)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (10.3.0)\nRequirement already satisfied: requests>=2.31.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.32.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (8.2.2)\nRequirement already satisfied: tiktoken>=0.3.3 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.7.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.5.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (4.11.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.9.0)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.14.1)\nRequirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /databricks/python3/lib/python3.12/site-packages (from llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.21.0)\nRequirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (0.1.27)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.9.3)\nRequirement already satisfied: azure-core>=1.31.0 in /databricks/python3/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.33.0)\nRequirement already satisfied: cryptography>=2.5 in /databricks/python3/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (42.0.5)\nRequirement already satisfied: msal>=1.30.0 in /databricks/python3/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.32.0)\nRequirement already satisfied: msal-extensions>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.3.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (8.1.7)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2023.10.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.9.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.8.2)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.3.0)\nRequirement already satisfied: certifi in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.0.8)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.26.16)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6bba6d07-0a35-4065-8d79-39a00c2a62a5/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.26.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2024.1)\nRequirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core>=1.31.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.16.0)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (24.1)\nRequirement already satisfied: PyJWT<3,>=1.0.0 in /usr/lib/python3/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (2.7.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.20.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (2.21)\nUsing cached llama_index_embeddings_azure_openai-0.1.11-py3-none-any.whl (3.3 kB)\nInstalling collected packages: llama-index-embeddings-azure-openai\nSuccessfully installed llama-index-embeddings-azure-openai-0.1.11\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "#Install prerequisite packages\n",
    "!pip install python-dotenv==1.0.0\n",
    "\n",
    "!pip install llama-index==0.10.59\n",
    "!pip install llama-index-llms-openai==0.1.27\n",
    "!pip install llama-index-embeddings-openai==0.1.11\n",
    "!pip install llama-index-llms-azure-openai==0.1.10\n",
    "!pip install llama-index-embeddings-azure-openai==0.1.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77f7952-5a00-44cc-9cc7-7623412ad8d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Setup Azure Open AI connection\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "from llama_index.core import Settings\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#API info. Replace with your own keys and end points\n",
    "api_key=\"\"\n",
    "azure_endpoint=\"\"\n",
    "azure_deployment=\"GPT4-O\"\n",
    "api_version=\"2024-12-01-preview\"\n",
    "\n",
    "#Setup the LLM\n",
    "Settings.llm=AzureOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=azure_deployment,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "#Setup the embedding model RAG\n",
    "Settings.embed_model= AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key='',\n",
    "    azure_endpoint='',\n",
    "    api_version='2023-05-15',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ac1604a-0a15-4254-af66-429a61d7c04b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-710c90cf1c3f4514b23cd8ad57991953\", \"tr-97620c7360604d81952bbbae00c738c4\"]",
      "text/plain": [
       "[Trace(request_id=tr-710c90cf1c3f4514b23cd8ad57991953), Trace(request_id=tr-97620c7360604d81952bbbae00c738c4)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import  VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Tool 1 : Function that returns the list of items in an order\n",
    "#-------------------------------------------------------------\n",
    "def get_order_items(order_id: int) -> List[str] :\n",
    "    \"\"\"Given an order Id, this function returns the \n",
    "    list of items purchased for that order\"\"\"\n",
    "    \n",
    "    order_items = {\n",
    "            1001: [\"Laptop\",\"Mouse\"],\n",
    "            1002: [\"Keyboard\",\"HDMI Cable\"],\n",
    "            1003: [\"Laptop\",\"Keyboard\"]\n",
    "        }\n",
    "    if order_id in order_items.keys():\n",
    "        return order_items[order_id]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Tool 2 : Function that returns the delivery date for an order\n",
    "#-------------------------------------------------------------\n",
    "def get_delivery_date(order_id: int) -> str:\n",
    "    \"\"\"Given an order Id, this function returns the \n",
    "    delivery date for that order\"\"\"\n",
    "\n",
    "    delivery_dates = {\n",
    "            1001: \"10-Jun\",\n",
    "            1002: \"12-Jun\",\n",
    "            1003: \"08-Jun\"       \n",
    "    }\n",
    "    if order_id in delivery_dates.keys():\n",
    "        return delivery_dates[order_id]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Tool 3 : Function that returns maximum return days for an item\n",
    "#----------------------------------------------------------------\n",
    "def get_item_return_days(item: str) -> int :\n",
    "    \"\"\"Given an Item, this function returns the return support\n",
    "    for that order. The return support is in number of days\"\"\"\n",
    "    \n",
    "    item_returns = {\n",
    "            \"Laptop\"     : 30,\n",
    "            \"Mouse\"      : 15,\n",
    "            \"Keyboard\"   : 15,\n",
    "            \"HDMI Cable\" : 5\n",
    "    }\n",
    "    if item in item_returns.keys():\n",
    "        return item_returns[item]\n",
    "    else:\n",
    "        #Default\n",
    "        return 45\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Tool 4 : Vector DB that contains customer support contacts\n",
    "#-------------------------------------------------------------\n",
    "#Setup vector index for return policies\n",
    "support_docs=SimpleDirectoryReader(input_files=[\"/Workspace/Users/yfatima1@optumcloud.com/Customer Service.pdf\"]).load_data()\n",
    "\n",
    "splitter=SentenceSplitter(chunk_size=1024)\n",
    "support_nodes=splitter.get_nodes_from_documents(support_docs)\n",
    "support_index=VectorStoreIndex(support_nodes)\n",
    "support_query_engine = support_index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc8b3d9-b9ed-4bcb-9d71-c71c644d9154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "#Create tools for the 3 functions and 1 index\n",
    "order_item_tool = FunctionTool.from_defaults(fn=get_order_items)\n",
    "delivery_date_tool = FunctionTool.from_defaults(fn=get_delivery_date)\n",
    "return_policy_tool = FunctionTool.from_defaults(fn=get_item_return_days)\n",
    "\n",
    "support_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=support_query_engine,\n",
    "    description=(\n",
    "        \"Customer support policies and contact information\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69aeeca4-abd7-4efb-8030-5a752b09512a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#Setup the Agent worker in LlamaIndex with all the Tools\n",
    "#This is the tool executor process\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [order_item_tool, \n",
    "     delivery_date_tool,\n",
    "     return_policy_tool,\n",
    "     support_tool\n",
    "    ], \n",
    "    llm=Settings.llm, \n",
    "    verbose=True\n",
    ")\n",
    "#Create an Agent Orchestrator with LlamaIndex\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2648ed41-81a4-40f2-8cb6-12148ee7fcdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the return policy for order number 1001\n=== Calling Function ===\nCalling function: get_order_items with args: {\"order_id\": 1001}\n=== Function Output ===\n['Laptop', 'Mouse']\n=== Calling Function ===\nCalling function: get_delivery_date with args: {\"order_id\": 1001}\n=== Function Output ===\n10-Jun\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:20:48 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\nCalling function: get_item_return_days with args: {\"item\": \"Laptop\"}\n=== Function Output ===\n30\n=== Calling Function ===\nCalling function: get_item_return_days with args: {\"item\": \"Mouse\"}\n=== Function Output ===\n15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:20:49 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\nFor order number 1001, the items purchased are a Laptop and a Mouse. The return policy for these items is as follows:\n\n- **Laptop**: You can return the laptop within 30 days from the delivery date.\n- **Mouse**: You can return the mouse within 15 days from the delivery date.\n\nThe delivery date for this order was June 10th.\n\n Final output : \n For order number 1001, the items purchased are a Laptop and a Mouse. The return policy for these items is as follows:\n\n- **Laptop**: You can return the laptop within 30 days from the delivery date.\n- **Mouse**: You can return the mouse within 15 days from the delivery date.\n\nThe delivery date for this order was June 10th.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-bc1810ebbc864c16a4c14e66fe5196ff\"",
      "text/plain": [
       "Trace(request_id=tr-bc1810ebbc864c16a4c14e66fe5196ff)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get return policy for an order\n",
    "response = agent.query(\n",
    "    \"What is the return policy for order number 1001\"\n",
    ")\n",
    "\n",
    "print(\"\\n Final output : \\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a751a15-0797-455e-a30b-25aff6de6af9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the return policy for order number 1004\n=== Calling Function ===\nCalling function: get_order_items with args: {\"order_id\": 1004}\n=== Function Output ===\n[]\n=== Calling Function ===\nCalling function: get_delivery_date with args: {\"order_id\": 1004}\n=== Function Output ===\n[]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:21:46 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\nCalling function: query_engine_tool with args: {\"input\": \"return policy\"}\n=== Function Output ===\nThe context does not provide information regarding the return policy.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 20:21:47 WARNING mlflow.openai._openai_autolog: Encountered unexpected error when ending trace: 2 validation errors for ChatMessage\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...tems'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ChatCompletionMessageTool...date'), type='function'), input_type=ChatCompletionMessageToolCall]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\nIt seems that there is no specific information available for order number 1004, and the general return policy details are not provided either. You may want to contact customer support for more information on return policies.\n\n Final output : \n It seems that there is no specific information available for order number 1004, and the general return policy details are not provided either. You may want to contact customer support for more information on return policies.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-b59bb30bb7d94ec193656a73e8a7dde9\"",
      "text/plain": [
       "Trace(request_id=tr-b59bb30bb7d94ec193656a73e8a7dde9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question about an invalid order number\n",
    "response = agent.query(\n",
    "    \"What is the return policy for order number 1004\"\n",
    ")\n",
    "\n",
    "print(\"\\n Final output : \\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0390e743-09ff-435b-b904-33377ed27c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Implementing Agentic AI for Customer Service",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
